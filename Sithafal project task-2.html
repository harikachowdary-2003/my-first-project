from bs4 import BeautifulSoup
import requests
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

def scrape_website(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')

    
    paragraphs = [p.text for p in soup.find_all('p')]
    headers = [h.text for h in soup.find_all(['h1', 'h2', 'h3'])]
    content = headers + paragraphs  

    
    chunks = [content[i:i+5] for i in range(0, len(content), 5)]  
    return [' '.join(chunk) for chunk in chunks]


def generate_embeddings(chunks):
    model = SentenceTransformer('all-MiniLM-L6-v2')
    embeddings = model.encode(chunks)
    return embeddings, model


def store_embeddings(embeddings, chunks):
    dimension = embeddings.shape[1]
    index = faiss.IndexFlatL2(dimension)
    index.add(embeddings) 
    return index, chunks


def query_website(index, query, model, chunks, top_k=3):
    query_embedding = model.encode([query])
    distances, indices = index.search(query_embedding, top_k)

    
    results = [chunks[i] for i in indices[0]]
    return results


def generate_response(query, results):
    response = f"Results for your query '{query}':\n\n"
    for i, res in enumerate(results, 1):
        response += f"Result {i}:\n{res}\n\n"
    return response


if _name_ == "_main_":
    
    urls = [
        "https://www.uchicago.edu/",
        "https://www.washington.edu/",
        "https://www.stanford.edu/",
        "https://und.edu/"
    ]

    
    all_chunks = []
    for url in urls:
        print(f"Scraping {url}...")
        all_chunks.extend(scrape_website(url))

    
    print("Generating embeddings...")
    embeddings, model = generate_embeddings(all_chunks)

    
    print("Storing embeddings in FAISS...")
    index, chunks = store_embeddings(embeddings, all_chunks)

    
    query = input("Please enter the query : ")
    results = query_website(index, query, model, chunks)

    
    print("Generating response...")
    response = generate_response(query, results)
   Â print(response)